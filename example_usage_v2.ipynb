{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\geopandas\\_compat.py:123: UserWarning: The Shapely GEOS version (3.11.2-CAPI-1.17.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ubach\\Projects\\GQA\\src\\utils.py:3: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import fiona\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from shapely.ops import unary_union\n",
    "from unidecode import unidecode\n",
    "import glob\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import dask.dataframe as dd\n",
    "import dask_geopandas as dg\n",
    "from dask.distributed import Client\n",
    "import gc\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\distributed\\node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 60021 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Path to data folders\n",
    "indata_f = r'P:\\Environment and Health\\Noise\\ServiceContract\\2024_ServiceContract\\QuietAreas'\n",
    "outdata_f = os.path.join(indata_f, 'OutputData', 'batch1')\n",
    "if not os.path.exists(outdata_f):\n",
    "    # Create the folder if it doesn't exist\n",
    "    os.makedirs(outdata_f)\n",
    "\n",
    "# 0 PREPARE A LOG FILE FOR QC\n",
    "log_file = 'log_GQA_Step1.csv'\n",
    "log_path = os.path.join(outdata_f, log_file)\n",
    "\n",
    "# Initialize Dask client\n",
    "client = Client()\n",
    "\n",
    "# Define engines\n",
    "engines = {\n",
    "    'fiona': {'engine': 'fiona'},\n",
    "    'pyogrio': {'engine': 'pyogrio'},\n",
    "    'pyogrio+arrow': {'engine': 'pyogrio', 'use_arrow': True}\n",
    "          \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 READ URBAN CENTRES\n",
    "# Read shapefile\n",
    "uc_file_path = os.path.join(indata_f, 'UrbanCentres', 'HDC2021_RG_Input.shp')\n",
    "# Read the GeoPackage file\n",
    "uc = gpd.read_file(uc_file_path)\n",
    "uc['CNTR_CODE'].fillna('AA', inplace=True)\n",
    "\n",
    "# Select cities for processing in this batch\n",
    "uc_sel = uc.query('Batch==1.0')\n",
    "# Read table to list the cities to process using urban centre code\n",
    "cities_ls = uc_sel.HDENS_CLST.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 READ NOISE DATA\n",
    "# Load agglomerations delineations\n",
    "agls_file_path = os.path.join(indata_f, 'NoiseData', 'DF1_5_Agglomerations_20240429.gpkg')\n",
    "\n",
    "# Read the GeoPackage file\n",
    "agls = gpd.read_file(agls_file_path, layer = 'dbo.DF15_AgglomerationSource_Valid_LatestDelivery', \n",
    "                     **engines['pyogrio+arrow'],columns=['agglomerationId_identifier', 'agglomerationName_nameEng', 'geometry'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read table with HDENS Urban centres information and Agglomerations link\n",
    "HDENS_AGGL_tbl = pd.read_csv(r'P:\\Environment and Health\\Noise\\ServiceContract\\2024_ServiceContract\\QuietAreas\\Processing\\UrbanCentres_Agglomerations_csv.csv')\n",
    "# Join uc code field to this table\n",
    "HDENS_AGGL_tbl = HDENS_AGGL_tbl.merge(uc[['POPL_2021', 'HDENS_CLST']], on='POPL_2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HDENS_NAME</th>\n",
       "      <th>HDENS_2011</th>\n",
       "      <th>POPL_2021</th>\n",
       "      <th>CNTR_CODE</th>\n",
       "      <th>agglomerationId_identifier</th>\n",
       "      <th>agglomerationName_nameEng</th>\n",
       "      <th>size</th>\n",
       "      <th>numberOfInhabitants</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>Batch</th>\n",
       "      <th>HDENS_CLST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Coru単a</td>\n",
       "      <td>GEOSTAT11_610</td>\n",
       "      <td>282450</td>\n",
       "      <td>ES</td>\n",
       "      <td>AG_ES_11_15030</td>\n",
       "      <td>A Coru単a</td>\n",
       "      <td>37.54</td>\n",
       "      <td>247046</td>\n",
       "      <td>ES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GEOSTAT21_610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aachen</td>\n",
       "      <td>GEOSTAT11_360</td>\n",
       "      <td>224750</td>\n",
       "      <td>DE</td>\n",
       "      <td>AG_DE_NW_13</td>\n",
       "      <td>Aachen</td>\n",
       "      <td>161.00</td>\n",
       "      <td>246443</td>\n",
       "      <td>DE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GEOSTAT21_360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aalborg</td>\n",
       "      <td>GEOSTAT11_031</td>\n",
       "      <td>149041</td>\n",
       "      <td>DK</td>\n",
       "      <td>AG_DK_00_4</td>\n",
       "      <td>Aalborg</td>\n",
       "      <td>66.00</td>\n",
       "      <td>138581</td>\n",
       "      <td>DK</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GEOSTAT21_031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aguadulce / La Gangosa</td>\n",
       "      <td></td>\n",
       "      <td>55615</td>\n",
       "      <td>ES</td>\n",
       "      <td>AG_ES_61_04079</td>\n",
       "      <td>Roquetas de Mar</td>\n",
       "      <td>20.82</td>\n",
       "      <td>106147</td>\n",
       "      <td>ES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GEOSTAT21_960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aix-en-Provence</td>\n",
       "      <td>GEOSTAT11_676</td>\n",
       "      <td>101708</td>\n",
       "      <td>FR</td>\n",
       "      <td>AG_FR_00_23</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>3149.22</td>\n",
       "      <td>1886800</td>\n",
       "      <td>FR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GEOSTAT21_676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               HDENS_NAME     HDENS_2011  POPL_2021 CNTR_CODE  \\\n",
       "0                A Coru単a  GEOSTAT11_610     282450        ES   \n",
       "1                  Aachen  GEOSTAT11_360     224750        DE   \n",
       "2                 Aalborg  GEOSTAT11_031     149041        DK   \n",
       "3  Aguadulce / La Gangosa                     55615        ES   \n",
       "4         Aix-en-Provence  GEOSTAT11_676     101708        FR   \n",
       "\n",
       "  agglomerationId_identifier agglomerationName_nameEng     size  \\\n",
       "0             AG_ES_11_15030                  A Coru単a    37.54   \n",
       "1                AG_DE_NW_13                    Aachen   161.00   \n",
       "2                 AG_DK_00_4                   Aalborg    66.00   \n",
       "3             AG_ES_61_04079           Roquetas de Mar    20.82   \n",
       "4                AG_FR_00_23                 Marseille  3149.22   \n",
       "\n",
       "   numberOfInhabitants countryCode  Batch     HDENS_CLST  \n",
       "0               247046          ES    NaN  GEOSTAT21_610  \n",
       "1               246443          DE    NaN  GEOSTAT21_360  \n",
       "2               138581          DK    1.0  GEOSTAT21_031  \n",
       "3               106147          ES    NaN  GEOSTAT21_960  \n",
       "4              1886800          FR    NaN  GEOSTAT21_676  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HDENS_AGGL_tbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HDENS_CLST</th>\n",
       "      <th>HDENS_NAME</th>\n",
       "      <th>HDENS_2011</th>\n",
       "      <th>POPL_2021</th>\n",
       "      <th>CNTR_CODE</th>\n",
       "      <th>MBRS_CODE_</th>\n",
       "      <th>SHAPE_AREA</th>\n",
       "      <th>SHAPE_LEN</th>\n",
       "      <th>Batch</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GEOSTAT21_018</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>GEOSTAT11_018</td>\n",
       "      <td>1462910.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>1</td>\n",
       "      <td>342000000.0</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>POLYGON ((4775000.000 4038000.000, 4774000.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GEOSTAT21_021</td>\n",
       "      <td>Tartu</td>\n",
       "      <td>GEOSTAT11_021</td>\n",
       "      <td>84168.0</td>\n",
       "      <td>EE</td>\n",
       "      <td>2</td>\n",
       "      <td>24000000.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>POLYGON ((5292000.000 4030000.000, 5290000.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GEOSTAT21_023</td>\n",
       "      <td>Stavanger</td>\n",
       "      <td>GEOSTAT11_023</td>\n",
       "      <td>196314.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>9</td>\n",
       "      <td>78000000.0</td>\n",
       "      <td>74000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>POLYGON ((4074000.000 3976000.000, 4073000.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GEOSTAT21_024</td>\n",
       "      <td>Norrk旦ping</td>\n",
       "      <td>GEOSTAT11_024</td>\n",
       "      <td>89963.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>1</td>\n",
       "      <td>25000000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>POLYGON ((4684000.000 3955000.000, 4683000.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GEOSTAT21_025</td>\n",
       "      <td>Link旦ping</td>\n",
       "      <td>GEOSTAT11_025</td>\n",
       "      <td>98073.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>1</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>POLYGON ((4655000.000 3932000.000, 4653000.000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HDENS_CLST  HDENS_NAME     HDENS_2011  POPL_2021 CNTR_CODE  MBRS_CODE_  \\\n",
       "0  GEOSTAT21_018   Stockholm  GEOSTAT11_018  1462910.0        SE           1   \n",
       "3  GEOSTAT21_021       Tartu  GEOSTAT11_021    84168.0        EE           2   \n",
       "5  GEOSTAT21_023   Stavanger  GEOSTAT11_023   196314.0        NO           9   \n",
       "6  GEOSTAT21_024  Norrk旦ping  GEOSTAT11_024    89963.0        SE           1   \n",
       "7  GEOSTAT21_025   Link旦ping  GEOSTAT11_025    98073.0        SE           1   \n",
       "\n",
       "    SHAPE_AREA  SHAPE_LEN  Batch  \\\n",
       "0  342000000.0   162000.0    1.0   \n",
       "3   24000000.0    24000.0    1.0   \n",
       "5   78000000.0    74000.0    1.0   \n",
       "6   25000000.0    28000.0    1.0   \n",
       "7   30000000.0    32000.0    1.0   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((4775000.000 4038000.000, 4774000.000...  \n",
       "3  POLYGON ((5292000.000 4030000.000, 5290000.000...  \n",
       "5  POLYGON ((4074000.000 3976000.000, 4073000.000...  \n",
       "6  POLYGON ((4684000.000 3955000.000, 4683000.000...  \n",
       "7  POLYGON ((4655000.000 3932000.000, 4653000.000...  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uc_sel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString\n",
    "from shapely.ops import snap, unary_union\n",
    "from shapely.errors import TopologicalError\n",
    "\n",
    "# Example LINESTRING geometries\n",
    "line1 = LineString([(4.77197e+06, 4.04444e+06), (4.77202e+06, 4.04478e+06)])\n",
    "line2 = LineString([(4.77198e+06, 4.04451e+06), (4.77198e+06, 4.04451e+06)])\n",
    "\n",
    "# Function to handle spatial operations with error capture\n",
    "def process_geometries(line1, line2):\n",
    "    try:\n",
    "        # Attempt to perform the spatial operation\n",
    "        result = unary_union([line1, line2])\n",
    "        print(\"Operation successful:\", result)\n",
    "    except TopologicalError as e:\n",
    "        print(\"Caught a TopologicalError:\", e)\n",
    "        # Handle the error, for example, by snapping geometries to a grid\n",
    "        tolerance = 0.0001  # Adjust as needed\n",
    "        snapped_line1 = snap(line1, line2, tolerance)\n",
    "        snapped_line2 = snap(line2, line1, tolerance)\n",
    "        try:\n",
    "            # Retry the spatial operation with snapped geometries\n",
    "            result = unary_union([snapped_line1, snapped_line2])\n",
    "            print(\"Operation successful after snapping:\", result)\n",
    "        except TopologicalError as e:\n",
    "            print(\"Caught another TopologicalError after snapping:\", e)\n",
    "            # Handle further if necessary or log the error\n",
    "            result = None\n",
    "    return result\n",
    "\n",
    "# Process the geometries\n",
    "result = process_geometries(line1, line2)\n",
    "if result:\n",
    "    print(\"Final result:\", result)\n",
    "else:\n",
    "    print(\"Failed to process geometries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2024-07-15 12:52:17.359563\n",
      "SE-GEOSTAT21_018-SE_a_ag0126-Huddinge\n",
      "1 country for this urban centre\n",
      "ncm\n"
     ]
    }
   ],
   "source": [
    "counter= 1\n",
    "agl_error_ls = []\n",
    "\n",
    "# Loop through test cities\n",
    "# Loop through test cities\n",
    "for uc_city_code in cities_ls:\n",
    "    print(counter)\n",
    "    start_time = datetime.now()\n",
    "    print(str(start_time))\n",
    "\n",
    "    HDENS_AGGL_city = HDENS_AGGL_tbl.query(f\"HDENS_CLST=='{uc_city_code}'\")\n",
    "    agl_id_city_ls = HDENS_AGGL_city.agglomerationId_identifier.values.astype(str).tolist()\n",
    "    for agl_id in agl_id_city_ls:\n",
    "        HDENS_AGGL_city_aglid = HDENS_AGGL_tbl.query(f\"HDENS_CLST=='{uc_city_code}' & agglomerationId_identifier=='{agl_id}'\")\n",
    "        ctry_code = HDENS_AGGL_city_aglid.CNTR_CODE.values.astype(str)[0]\n",
    "        aglo_name = HDENS_AGGL_city_aglid.agglomerationName_nameEng.values.astype(str)[0]\n",
    "        city_agl_cd = f\"{ctry_code}-{uc_city_code}-{agl_id}-{aglo_name}\"\n",
    "        print(city_agl_cd)\n",
    "        if len(ctry_code.split('-'))>1:\n",
    "               print('>1 countries')\n",
    "               agl_error_ls.append(city_agl_cd + \" bordering countries\")\n",
    "        else:\n",
    "            print('1 country for this urban centre')      \n",
    "            # Load agglomeration boundary for selected city\n",
    "            agl_city = agls.query(f'agglomerationId_identifier == \"{agl_id}\"')\n",
    "            if agl_city.empty:\n",
    "                agglomerationId_identifier = 'NotAvailable'\n",
    "                print (\"agglomerationId_identifier Not Available\")\n",
    "                agl_error_ls.append(city_agl_cd + \" agglomerationId_identifier Not Available\")\n",
    "            else:\n",
    "                output_path = os.path.join(outdata_f, f'{city_agl_cd}_GQA_centroids.shp')\n",
    "                if not os.path.exists(output_path):\n",
    "                    try:\n",
    "                        # Check noise contour maps GeoPackage file\n",
    "                        ncm_file_path = os.path.join(indata_f, 'NoiseData', f'Noise_20202025_export.gpkg')\n",
    "                        layerName = f'dbo.DF48_agg_NoiseContours_roadsInAgglomeration_Lden_Valid_LatestDelivery_Poly_{ctry_code}'           \n",
    "                        #ncm_file_path = os.path.join(indata_f, 'NoiseData', f'Noise_20202025_export_{ctry_code}.gpkg')\n",
    "                        #layerName = f'dbo.DF48_agg_NoiseContours_roadsInAgglomeration_Lden_Valid_LatestDelivery_Poly_{ctry_code}'\n",
    "                        #layerName = f'dbodf48_agg_noisecontours_roadsinagglomeration_lden_valid_latestdelivery_poly_{ctry_code}'\n",
    "                        ncm = gpd.read_file(ncm_file_path, layer=layerName, columns=['category', 'geometry'], \n",
    "                                            engine='pyogrio', use_arrow=True, bbox= tuple(agl_city.total_bounds))\n",
    "                        print (\"ncm\")\n",
    "\n",
    "                        # Perform spatial overlay (intersection) \n",
    "                        ncm_agl = gpd.overlay(ncm, agl_city, how='intersection')\n",
    "                        print (\"ncm_agl\")\n",
    "\n",
    "                        # Aggregate the area with lower band values (quieter bands)\n",
    "                        ncm_agl_city = gpd.overlay(ncm_agl, agl_city, how='union')\n",
    "                        ncm_agl_city.category.fillna(0)\n",
    "\n",
    "                        # Select a subset of columns of interest\n",
    "                        ncm_dis = ncm_agl_city[['category', 'geometry']]\n",
    "                        \n",
    "                        # Define the list of noisy classes\n",
    "                        noisy_classes = ['Lden5559', 'Lden6064', 'Lden6569', 'Lden7074', 'LdenGreaterThan75']\n",
    "\n",
    "                        # Create a condition based on the category column\n",
    "                        condition = ncm_dis['category'].isin(noisy_classes)  # Replace 'category_column' with the actual column name\n",
    "\n",
    "                        # Specify the condition and create a new category column based on the condition\n",
    "                        ncm_dis['noisy'] = 0\n",
    "                        ncm_dis.loc[condition, 'noisy'] = 1\n",
    "                        ncm_dis = ncm_dis[['noisy', 'geometry']]\n",
    "                        ncm_dis_dg = dg.from_geopandas(ncm_dis, npartitions=10)\n",
    "                        ncm_dis = ncm_dis_dg.dissolve(by='noisy').compute().reset_index()\n",
    "                        print (\"ncm_dis\")\n",
    "\n",
    "                        # 3 READ UA DATA        \n",
    "                        # Load GeoPackage info\n",
    "                        data_f = r'A:\\Copernicus\\UrbanAtlas\\UrbanAtlas\\UA2018'\n",
    "                        uc_city = uc_sel.query(f'HDENS_CLST == \"{uc_city_code}\"')\n",
    "                        ctry_code = uc_city.CNTR_CODE.values.astype(str)[0] \n",
    "                        city_unicodeName_upper = unidecode(cityLocalName).upper()\n",
    "                        folder_path = glob.glob(os.path.join(data_f, f'{ctry_code}*{city_unicodeName_upper}*'))\n",
    "                        ua_file_path =  glob.glob(os.path.join(folder_path[0], 'Data', f'{ctry_code}*{city_unicodeName_upper}*.gpkg'))\n",
    "                        layers_ls = fiona.listlayers(ua_file_path[0])\n",
    "                        print (\"layers_ls\")\n",
    "\n",
    "                        # Read the GeoPackage file\n",
    "                        ua = gpd.read_file(ua_file_path[0], layer= layers_ls[0], \n",
    "                                        columns= ['country', 'fua_name', 'fua_code','code_2018', 'class_2018', 'geometry'], engine='pyogrio', \n",
    "                                        use_arrow=True, bbox= tuple(uc_city.total_bounds))\n",
    "                        print (\"loaded ua in urban city\")\n",
    "\n",
    "                        # Select 'green' classes\n",
    "                        uagreen = ua.query('code_2018 == \"14100\" or code_2018 == \"31000\"')\n",
    "                        \n",
    "                        # 4 SELECT UA INTERSECTING UC\n",
    "                        # Perform spatial overlay (intersection)\n",
    "                        uagreen_urbc = gpd.overlay(uagreen, uc_city, how='intersection')\n",
    "\n",
    "                        # 5 IDENTIFY GREEN AREAS EXCLUDED (NOT COVERED BY NCM)\n",
    "                        # Perform spatial overlay (intersection)\n",
    "                        nqgreen = gpd.overlay(uagreen_urbc, ncm_dis, how='intersection') #noisy/quiet green\n",
    "                        not_covered = uagreen_urbc.geometry.difference(uagreen_urbc.geometry.intersection(nqgreen.geometry.unary_union))\n",
    "                        # Filter out empty polygons(not empty polygons)\n",
    "                        green_not_covered_by_ncm = not_covered[~not_covered.is_empty]\n",
    "\n",
    "                        # save to shapefile\n",
    "                        file_path = os.path.join(outdata_f, f'{city_agl_cd}_green_not_covered_by_ncm.shp')\n",
    "                        green_not_covered_by_ncm.to_file(file_path, driver='ESRI Shapefile')\n",
    "                        print (\"green_not_covered_by_ncm\")\n",
    "\n",
    "                        # 6 IDENTIFY QUIET/NOISY AREAS\n",
    "                        ## for statistics need to calculate area again\n",
    "                        # Calculate the area for each geometry and create a new column 'area'\n",
    "                        nqgreen['area_m2'] = nqgreen['geometry'].area\n",
    "                        nqgreen['area_ha'] = round(nqgreen['area_m2']* 0.0001,2)\n",
    "                        nqgreen['area_km2'] = round(nqgreen['area_ha']* 0.01,2)\n",
    "                        nqgreen_area = nqgreen.groupby(['code_2018', 'noisy'])['area_m2'].sum().reset_index()\n",
    "                        nqgreen_area['area_ha'] = round(nqgreen_area['area_m2']* 0.0001,2)\n",
    "                        nqgreen_area['area_km2'] = round(nqgreen_area['area_ha']* 0.01,2)\n",
    "\n",
    "                        # 7 EXPORT GREEN QUIET AREAS (GQA)\n",
    "                        nqgreen = nqgreen[['country', 'fua_name', 'fua_code', 'HDENS_2011', 'code_2018', 'class_2018', 'noisy',  'area_m2', 'area_ha', 'area_km2', 'geometry']]\n",
    "                        GQA = nqgreen.query('noisy == 0')\n",
    "                        GNA = nqgreen.query('noisy == 1')\n",
    "\n",
    "                        # Export to shapefile\n",
    "                        file_path = os.path.join(outdata_f, f'{city_agl_cd}_GQA.shp')\n",
    "                        GQA.to_file(file_path, driver='ESRI Shapefile')\n",
    "                        print (\"GQA\")\n",
    "\n",
    "                        # 8 CREATE CENTROIDS FOR GQA POLYGONS\n",
    "                        # Create a new GeoDataFrame with centroids as points\n",
    "                        GQA_pts = gpd.GeoDataFrame(geometry=GQA['geometry'].centroid)\n",
    "                        GQA_pts['oid'] = GQA.index\n",
    "                        GQA_pts['fua_name'] = GQA.fua_name\n",
    "                        GQA_pts['fua_code'] = GQA.fua_code\n",
    "                        GQA_pts['HDENS_2011'] = GQA.HDENS_2011\n",
    "\n",
    "                        # Export to shapefile\n",
    "                        file_path = os.path.join(outdata_f, f'{city_agl_cd}_GQA_centroids.shp')\n",
    "                        GQA_pts.to_file(file_path, driver='ESRI Shapefile')\n",
    "\n",
    "                        print (\"GQA_pts\")\n",
    "                \n",
    "                        # Calculate the duration\n",
    "                        end_time = datetime.now()\n",
    "                        processing_time = end_time - start_time\n",
    "\n",
    "                        print (\"str(processing_time)\")\n",
    "                        \n",
    "                        ## write output values into log file\n",
    "                        uc_km2 = round(uc_city.area.sum()/1000000,2)\n",
    "                        agl_city_km2 = round(agl_city.area.sum()/1000000,2)\n",
    "                        ncm_agl_city_km2 = round(ncm_agl_city.area.sum()/1000000,2)\n",
    "                        ua_km2 = round(ua.area.sum()/1000000,2)\n",
    "                        uagreen_km2 = round(uagreen.area.sum()/1000000,2)\n",
    "                        uagreen_urbc_km2 = round(uagreen_urbc.area.sum()/1000000,2)\n",
    "                        nqgreen_m2 = round(nqgreen.area.sum(),2)\n",
    "                        green_not_covered_by_ncm_m2 = round(green_not_covered_by_ncm.area.sum(),2)\n",
    "                        GQA_m2 = round(GQA.area.sum(),2)\n",
    "                        GNA_m2 = round(GNA.area.sum(),2)\n",
    "                        processing_duration = str(processing_time)\n",
    "\n",
    "                        log_entry = create_log_entry(cityLocalName, agglomerationId_identifier, uc_km2, agl_city_km2, \n",
    "                                                ncm_agl_city_km2,ua_km2, uagreen_km2, uagreen_urbc_km2, nqgreen_m2, \n",
    "                                                green_not_covered_by_ncm_m2, GQA_m2, GNA_m2, processing_time)\n",
    "                        write_log(log_path, log_entry)\n",
    "                    except TopologicalError as e:\n",
    "                        print(\"Caught another TopologicalError after snapping:\", e)\n",
    "                        agl_error_ls.append(city_agl_cd, \" Topological error \", e)\n",
    "\n",
    "                    # Clean up intermediate variables to free memory\n",
    "                    del agl_city, ncm, ncm_agl, ncm_agl_city, ncm_dis, ua, uagreen, uagreen_urbc, nqgreen, green_not_covered_by_ncm, GQA, GNA, GQA_pts\n",
    "    counter= counter+1\n",
    "\n",
    "print(agl_error_ls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_ETC_DI_v4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
