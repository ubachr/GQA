{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\geopandas\\_compat.py:123: UserWarning: The Shapely GEOS version (3.11.2-CAPI-1.17.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ubach\\Projects\\GQA\\src\\utils.py:3: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import fiona\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from shapely.ops import unary_union\n",
    "from shapely.errors import TopologicalError\n",
    "from unidecode import unidecode\n",
    "import glob\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import dask.dataframe as dd\n",
    "import dask_geopandas as dg\n",
    "from dask.distributed import Client\n",
    "import gc\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data folders\n",
    "indata_f = r'P:\\Environment and Health\\Noise\\ServiceContract\\2024_ServiceContract\\QuietAreas'\n",
    "outdata_f = os.path.join(indata_f, 'OutputData', 'batch1_allprocessed')\n",
    "if not os.path.exists(outdata_f):\n",
    "    # Create the folder if it doesn't exist\n",
    "    os.makedirs(outdata_f)\n",
    "\n",
    "# 0 PREPARE A LOG FILE FOR QC\n",
    "log_file = 'log_GQA_Step1.csv'\n",
    "log_path = os.path.join(outdata_f, log_file)\n",
    "\n",
    "# Initialize Dask client\n",
    "client = Client()\n",
    "\n",
    "# Define engines\n",
    "engines = {\n",
    "    'fiona': {'engine': 'fiona'},\n",
    "    'pyogrio': {'engine': 'pyogrio'},\n",
    "    'pyogrio+arrow': {'engine': 'pyogrio', 'use_arrow': True}\n",
    "          \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 COMMON SOURCES FOR ALL DATA\n",
    "# URBAN CENTRES\n",
    "# Read shapefile\n",
    "uc_file_path = os.path.join(indata_f, 'UrbanCentres', 'HDC2021_RG_Input.shp')\n",
    "# Read the GeoPackage file\n",
    "uc = gpd.read_file(uc_file_path)\n",
    "uc['CNTR_CODE'].fillna('AA', inplace=True)\n",
    "\n",
    "# Select cities for processing in this batch\n",
    "uc_sel = uc.query('Batch==1.0 & CNTR_CODE != \"SE\"')\n",
    "uc_sel = uc_sel.sort_values(by='CNTR_CODE')\n",
    "\n",
    "# Read table to list the cities to process using urban centre code\n",
    "cities_ls = uc_sel.HDENS_CLST.tolist()\n",
    "\n",
    "# NOISE DATA\n",
    "# Load agglomerations delineations\n",
    "agls_file_path = os.path.join(indata_f, 'NoiseData', 'DF1_5_Agglomerations_20240429.gpkg')\n",
    "\n",
    "# Read the GeoPackage file\n",
    "agls = gpd.read_file(agls_file_path, layer = 'dbo.DF15_AgglomerationSource_Valid_LatestDelivery', \n",
    "                     **engines['pyogrio+arrow'],columns=['agglomerationId_identifier', 'agglomerationName_nameEng', 'geometry'])\n",
    "\n",
    "# URBAN ATLAS\n",
    "# Read table with HDENS Urban centres information and Agglomerations link\n",
    "HDENS_AGGL_tbl = pd.read_csv(r'P:\\Environment and Health\\Noise\\ServiceContract\\2024_ServiceContract\\QuietAreas\\Processing\\UrbanCentres_Agglomerations_csv.csv')\n",
    "# Join uc code field to this table\n",
    "HDENS_AGGL_tbl = HDENS_AGGL_tbl.merge(uc[['POPL_2021', 'HDENS_CLST']], on='POPL_2021')\n",
    "\n",
    "# TRANSLATOR TABLE\n",
    "# Crosswalk table containing the different codes from input sources\n",
    "codes_path = r'P:\\Environment and Health\\Noise\\ServiceContract\\2024_ServiceContract\\QuietAreas\\Processing\\Codes.csv'\n",
    "codes = pd.read_csv(codes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2024-07-16 11:15:28.880723\n",
      "AT-GEOSTAT21_481-AG_AT_00_1-Wien\n",
      "1 country for this urban centre\n",
      "Error AT-GEOSTAT21_481-AG_AT_00_1-Wien\n",
      "2\n",
      "2024-07-16 11:15:30.425732\n",
      "AT-GEOSTAT21_520-AG_AT_00_5-Innsbruck\n",
      "1 country for this urban centre\n",
      "Error AT-GEOSTAT21_520-AG_AT_00_5-Innsbruck\n",
      "3\n",
      "2024-07-16 11:15:30.756729\n",
      "AT-GEOSTAT21_522-AG_AT_00_2-Graz\n",
      "1 country for this urban centre\n",
      "Error AT-GEOSTAT21_522-AG_AT_00_2-Graz\n",
      "4\n",
      "2024-07-16 11:15:31.028732\n",
      "AT-GEOSTAT21_479-AG_AT_00_3-Linz\n",
      "1 country for this urban centre\n",
      "Error AT-GEOSTAT21_479-AG_AT_00_3-Linz\n",
      "5\n",
      "2024-07-16 11:15:31.251733\n",
      "AT-GEOSTAT21_495-AG_AT_00_4-Salzburg\n",
      "1 country for this urban centre\n",
      "Error AT-GEOSTAT21_495-AG_AT_00_4-Salzburg\n",
      "6\n",
      "2024-07-16 11:15:31.513736\n",
      "BE-GEOSTAT21_344-AG_BE_FL_4-Leuven\n",
      "1 country for this urban centre\n",
      "ncm\n",
      "ncm_dis\n",
      "ncm_agl\n",
      "union\n",
      "fillna\n",
      "   noisy                                           geometry\n",
      "0    1.0  MULTIPOLYGON (((3947501.323 3104385.987, 39474...\n",
      "1    0.0  MULTIPOLYGON (((3953341.072 3099159.668, 39533...\n",
      "LEUVEN\n",
      "layers_ls\n",
      "loaded ua in urban city\n",
      "green_not_covered_by_ncm\n",
      "GQA\n",
      "GQA_pts\n",
      "str(processing_time)\n",
      "7\n",
      "2024-07-16 11:16:28.514905\n",
      "BE-GEOSTAT21_349-AG_BE_BR_1-Brussels-Capital\n",
      "1 country for this urban centre\n",
      "ncm\n",
      "ncm_dis\n",
      "ncm_agl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Q:\\UserTemp\\ubach\\AppData\\Local\\Temp\\4\\ipykernel_564076\\4042648961.py:63: UserWarning: `keep_geom_type=True` in overlay resulted in 11512 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  ncm_agl_city = gpd.overlay(ncm_agl, agl_city, how='union')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "union\n",
      "fillna\n",
      "   noisy                                           geometry\n",
      "0    1.0  MULTIPOLYGON (((3919289.635 3098597.452, 39192...\n",
      "1    0.0  MULTIPOLYGON (((3931963.720 3094028.177, 39319...\n",
      "2    1.0  MULTIPOLYGON (((3929664.983 3101842.205, 39296...\n",
      "3    0.0  POLYGON ((3922626.902 3089166.388, 3922626.377...\n",
      "4    0.0  MULTIPOLYGON (((3919353.963 3093160.513, 39193...\n",
      "BRUXELLES / BRUSSEL\n",
      "Error BE-GEOSTAT21_349-AG_BE_BR_1-Brussels-Capital\n",
      "8\n",
      "2024-07-16 11:35:14.642737\n",
      "BE-GEOSTAT21_332-AG_BE_FL_2-Ghent\n",
      "1 country for this urban centre\n",
      "ncm\n",
      "ncm_dis\n",
      "ncm_agl\n",
      "union\n",
      "fillna\n",
      "   noisy                                           geometry\n",
      "0    1.0  MULTIPOLYGON (((3891018.532 3133688.091, 38910...\n",
      "1    0.0  MULTIPOLYGON (((3889972.805 3135730.187, 38900...\n",
      "GENT\n",
      "layers_ls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 11:37:16,730 - distributed.protocol.core - CRITICAL - Failed to Serialize\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\distributed\\protocol\\core.py\", line 109, in dumps\n",
      "    frames[0] = msgpack.dumps(msg, default=_encode_default, use_bin_type=True)\n",
      "  File \"c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\msgpack\\__init__.py\", line 38, in packb\n",
      "    return Packer(**kwargs).pack(o)\n",
      "  File \"msgpack/_packer.pyx\", line 120, in msgpack._cmsgpack.Packer.__cinit__\n",
      "MemoryError: Unable to allocate internal buffer.\n",
      "2024-07-16 11:37:16,739 - distributed.comm.utils - ERROR - Unable to allocate internal buffer.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\distributed\\comm\\utils.py\", line 55, in _to_frames\n",
      "    return list(protocol.dumps(msg, **kwargs))\n",
      "  File \"c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\distributed\\protocol\\core.py\", line 109, in dumps\n",
      "    frames[0] = msgpack.dumps(msg, default=_encode_default, use_bin_type=True)\n",
      "  File \"c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\msgpack\\__init__.py\", line 38, in packb\n",
      "    return Packer(**kwargs).pack(o)\n",
      "  File \"msgpack/_packer.pyx\", line 120, in msgpack._cmsgpack.Packer.__cinit__\n",
      "MemoryError: Unable to allocate internal buffer.\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-685' coro=<Server._handle_comm() done, defined at c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\distributed\\core.py:726> exception=MemoryError('Unable to allocate internal buffer.')>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\distributed\\core.py\", line 838, in _handle_comm\n",
      "    await comm.write(result, serializers=serializers)\n",
      "  File \"c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\distributed\\comm\\tcp.py\", line 271, in write\n",
      "    frames = await to_frames(\n",
      "  File \"c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\distributed\\comm\\utils.py\", line 72, in to_frames\n",
      "    return _to_frames()\n",
      "  File \"c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\distributed\\comm\\utils.py\", line 55, in _to_frames\n",
      "    return list(protocol.dumps(msg, **kwargs))\n",
      "  File \"c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\distributed\\protocol\\core.py\", line 109, in dumps\n",
      "    frames[0] = msgpack.dumps(msg, default=_encode_default, use_bin_type=True)\n",
      "  File \"c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\msgpack\\__init__.py\", line 38, in packb\n",
      "    return Packer(**kwargs).pack(o)\n",
      "  File \"msgpack/_packer.pyx\", line 120, in msgpack._cmsgpack.Packer.__cinit__\n",
      "MemoryError: Unable to allocate internal buffer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ua in urban city\n",
      "green_not_covered_by_ncm\n",
      "GQA\n",
      "GQA_pts\n",
      "str(processing_time)\n",
      "9\n",
      "2024-07-16 11:37:47.563346\n",
      "BE-GEOSTAT21_317-AG_BE_FL_1-Antwerp\n",
      "1 country for this urban centre\n",
      "ncm\n",
      "ncm_dis\n",
      "ncm_agl\n",
      "union\n",
      "fillna\n",
      "   noisy                                           geometry\n",
      "0    1.0  MULTIPOLYGON (((3924478.284 3144333.835, 39244...\n",
      "1    0.0  MULTIPOLYGON (((3937022.394 3137854.964, 39370...\n",
      "ANTWERPEN\n",
      "layers_ls\n",
      "loaded ua in urban city\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\pygeos\\set_operations.py:129: RuntimeWarning: invalid value encountered in intersection\n",
      "  return lib.intersection(a, b, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green_not_covered_by_ncm\n",
      "GQA\n",
      "GQA_pts\n",
      "str(processing_time)\n",
      "10\n",
      "2024-07-16 11:41:59.721515\n",
      "BE-GEOSTAT21_364-AG_BE_WA_2-Liege\n",
      "1 country for this urban centre\n",
      "ncm\n",
      "ncm_dis\n",
      "ncm_agl\n",
      "Error BE-GEOSTAT21_364-AG_BE_WA_2-Liege\n",
      "11\n",
      "2024-07-16 11:42:00.096521\n",
      "BE-GEOSTAT21_300-AG_BE_FL_1-Antwerp\n",
      "1 country for this urban centre\n",
      "ncm\n",
      "ncm_dis\n",
      "ncm_agl\n",
      "union\n",
      "fillna\n",
      "   noisy                                           geometry\n",
      "0    1.0  MULTIPOLYGON (((3924478.284 3144333.835, 39244...\n",
      "1    0.0  MULTIPOLYGON (((3937022.394 3137854.964, 39370...\n",
      "KAPELLEN / EKEREN\n",
      "Error BE-GEOSTAT21_300-AG_BE_FL_1-Antwerp\n",
      "12\n",
      "2024-07-16 11:43:41.019355\n",
      "CH-GEOSTAT21_542-AG_CH_00_9-Lausanne\n",
      "1 country for this urban centre\n",
      "ncm\n",
      "ncm_dis\n",
      "ncm_agl\n",
      "union\n",
      "fillna\n",
      "   noisy                                           geometry\n",
      "0    1.0  MULTIPOLYGON (((4083186.237 2610452.258, 40831...\n",
      "1    0.0  MULTIPOLYGON (((4080738.791 2611935.683, 40810...\n",
      "LAUSANNE\n",
      "layers_ls\n",
      "loaded ua in urban city\n",
      "green_not_covered_by_ncm\n",
      "GQA\n",
      "GQA_pts\n",
      "str(processing_time)\n",
      "13\n",
      "2024-07-16 11:46:19.019956\n",
      "CH-GEOSTAT21_521-AG_CH_00_2-Zurich\n",
      "1 country for this urban centre\n",
      "ncm\n",
      "ncm_dis\n",
      "ncm_agl\n",
      "union\n",
      "fillna\n",
      "   noisy                                           geometry\n",
      "0    1.0  MULTIPOLYGON (((4238387.348 2690203.676, 42383...\n",
      "1    0.0  MULTIPOLYGON (((4213023.392 2691976.316, 42130...\n",
      "ZURICH\n",
      "layers_ls\n",
      "loaded ua in urban city\n",
      "green_not_covered_by_ncm\n",
      "GQA\n",
      "GQA_pts\n",
      "str(processing_time)\n",
      "14\n",
      "2024-07-16 11:55:59.603222\n",
      "CH-GEOSTAT21_528-AG_CH_00_3-Bern\n",
      "1 country for this urban centre\n",
      "ncm\n",
      "ncm_dis\n",
      "ncm_agl\n",
      "union\n",
      "fillna\n",
      "   noisy                                           geometry\n",
      "0    1.0  MULTIPOLYGON (((4143368.080 2645855.377, 41433...\n",
      "1    0.0  MULTIPOLYGON (((4143653.397 2645757.466, 41436...\n",
      "BERN\n",
      "layers_ls\n",
      "loaded ua in urban city\n",
      "green_not_covered_by_ncm\n",
      "GQA\n",
      "GQA_pts\n",
      "str(processing_time)\n",
      "15\n",
      "2024-07-16 11:58:16.326582\n",
      "CH-DE-GEOSTAT21_510-AG_CH_00_5-Basel\n",
      ">1 countries\n",
      "16\n",
      "2024-07-16 11:58:16.344610\n",
      "CH-FR-GEOSTAT21_549-AG_CH_00_10-Geneva\n",
      ">1 countries\n",
      "17\n",
      "2024-07-16 11:58:16.349600\n",
      "CY-GEOSTAT21_843-AG_CY_00_1-Nicosia\n",
      "1 country for this urban centre\n",
      "ncm\n",
      "Error CY-GEOSTAT21_843-AG_CY_00_1-Nicosia\n",
      "18\n",
      "2024-07-16 11:58:21.093617\n",
      "CY-GEOSTAT21_845-AG_CY_00_4-Larnaca\n",
      "1 country for this urban centre\n",
      "ncm\n",
      "Error CY-GEOSTAT21_845-AG_CY_00_4-Larnaca\n",
      "19\n",
      "2024-07-16 11:58:23.403627\n",
      "CY-GEOSTAT21_856-AG_CY_00_5-Limassol\n",
      "1 country for this urban centre\n",
      "ncm\n",
      "Error CY-GEOSTAT21_856-AG_CY_00_5-Limassol\n",
      "20\n",
      "2024-07-16 11:58:24.889630\n",
      "CZ-GEOSTAT21_362-AG_CZ_00_004-Usti nad Labem - Teplice\n",
      "1 country for this urban centre\n",
      "ncm\n",
      "ncm_dis\n",
      "ncm_agl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Q:\\UserTemp\\ubach\\AppData\\Local\\Temp\\4\\ipykernel_564076\\4042648961.py:63: UserWarning: `keep_geom_type=True` in overlay resulted in 508 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  ncm_agl_city = gpd.overlay(ncm_agl, agl_city, how='union')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "union\n",
      "fillna\n",
      "   noisy                                           geometry\n",
      "0    0.0  MULTIPOLYGON (((4611869.229 3071513.709, 46118...\n",
      "1    1.0  MULTIPOLYGON (((4590586.822 3063083.649, 45905...\n",
      "2    0.0  MULTIPOLYGON (((4613076.140 3071414.249, 46130...\n",
      "USTI NAD LABEM\n",
      "Error CZ-GEOSTAT21_362-AG_CZ_00_004-Usti nad Labem - Teplice\n",
      "['AT-GEOSTAT21_481-AG_AT_00_1-Wien Topological error', 'AT-GEOSTAT21_520-AG_AT_00_5-Innsbruck Topological error', 'AT-GEOSTAT21_522-AG_AT_00_2-Graz Topological error', 'AT-GEOSTAT21_479-AG_AT_00_3-Linz Topological error', 'AT-GEOSTAT21_495-AG_AT_00_4-Salzburg Topological error', 'BE-GEOSTAT21_349-AG_BE_BR_1-Brussels-Capital Topological error', 'BE-GEOSTAT21_364-AG_BE_WA_2-Liege Topological error', 'BE-GEOSTAT21_300-AG_BE_FL_1-Antwerp Topological error', 'CH-DE-GEOSTAT21_510-AG_CH_00_5-Basel bordering countries', 'CH-FR-GEOSTAT21_549-AG_CH_00_10-Geneva bordering countries', 'CY-GEOSTAT21_843-AG_CY_00_1-Nicosia Topological error', 'CY-GEOSTAT21_845-AG_CY_00_4-Larnaca Topological error', 'CY-GEOSTAT21_856-AG_CY_00_5-Limassol Topological error', 'CZ-GEOSTAT21_362-AG_CZ_00_004-Usti nad Labem - Teplice Topological error']\n"
     ]
    }
   ],
   "source": [
    "counter= 1\n",
    "agl_error_ls = []\n",
    "\n",
    "\n",
    "# Loop through test cities\n",
    "for uc_city_code in cities_ls:\n",
    "    print(counter)\n",
    "    start_time = datetime.now()\n",
    "    print(str(start_time))\n",
    "\n",
    "    HDENS_AGGL_city = HDENS_AGGL_tbl.query(f\"HDENS_CLST=='{uc_city_code}'\")\n",
    "    agl_id_city_ls = HDENS_AGGL_city.agglomerationId_identifier.values.astype(str).tolist()\n",
    "    for agl_id in agl_id_city_ls:\n",
    "        HDENS_AGGL_city_aglid = HDENS_AGGL_tbl.query(f\"HDENS_CLST=='{uc_city_code}' & agglomerationId_identifier=='{agl_id}'\")\n",
    "        ctry_code = HDENS_AGGL_city_aglid.CNTR_CODE.values.astype(str)[0]\n",
    "        aglo_name = HDENS_AGGL_city_aglid.agglomerationName_nameEng.values.astype(str)[0]\n",
    "        city_agl_cd = f\"{ctry_code}-{uc_city_code}-{agl_id}-{aglo_name}\"\n",
    "        print(city_agl_cd)\n",
    "        if len(ctry_code.split('-'))>1:\n",
    "               print('>1 countries')\n",
    "               agl_error_ls.append(city_agl_cd + \" bordering countries\")\n",
    "        else:\n",
    "            print('1 country for this urban centre')      \n",
    "            # Load agglomeration boundary for selected city\n",
    "            agl_city = agls.query(f'agglomerationId_identifier == \"{agl_id}\"')\n",
    "            if agl_city.empty:\n",
    "                agglomerationId_identifier = 'NotAvailable'\n",
    "                print (\"agglomerationId_identifier Not Available\")\n",
    "                agl_error_ls.append(city_agl_cd + \" agglomerationId_identifier Not Available\")\n",
    "            else:\n",
    "                output_path = os.path.join(outdata_f, f'{city_agl_cd}_GQA_centroids.shp')\n",
    "                if not os.path.exists(output_path):\n",
    "                    try:\n",
    "                        # Check noise contour maps GeoPackage file\n",
    "                        ncm_file_path = os.path.join(indata_f, 'NoiseData', f'Noise_20202025_export.gpkg')\n",
    "                        layerName = f'dbo.DF48_agg_NoiseContours_roadsInAgglomeration_Lden_Valid_LatestDelivery_Poly_{ctry_code}'           \n",
    "                        #ncm_file_path = os.path.join(indata_f, 'NoiseData', f'Noise_20202025_export_{ctry_code}.gpkg')\n",
    "                        #layerName = f'dbo.DF48_agg_NoiseContours_roadsInAgglomeration_Lden_Valid_LatestDelivery_Poly_{ctry_code}'\n",
    "                        #layerName = f'dbodf48_agg_noisecontours_roadsinagglomeration_lden_valid_latestdelivery_poly_{ctry_code}'\n",
    "                        ncm = gpd.read_file(ncm_file_path, layer=layerName, columns=['category', 'geometry'], \n",
    "                                            engine='pyogrio', use_arrow=True, bbox= tuple(agl_city.total_bounds))\n",
    "                        print (\"ncm\")\n",
    "\n",
    "                        # Define the list of noisy classes\n",
    "                        noisy_classes = ['Lden5559', 'Lden6064', 'Lden6569', 'Lden7074', 'LdenGreaterThan75']\n",
    "\n",
    "                        # Create a condition based on the category column\n",
    "                        condition = ncm['category'].isin(noisy_classes)  # Replace 'category_column' with the actual column name\n",
    "\n",
    "                        # Specify the condition and create a new category column based on the condition\n",
    "                        ncm['noisy'] = 0\n",
    "                        ncm.loc[condition, 'noisy'] = 1\n",
    "                        ncm = ncm[['noisy', 'geometry']]\n",
    "                        ncm_dis_dg = dg.from_geopandas(ncm, npartitions=10)\n",
    "                        ncm_dis = ncm_dis_dg.dissolve(by='noisy').compute().reset_index()\n",
    "                        print (\"ncm_dis\")\n",
    "\n",
    "                        # Perform spatial overlay (intersection) \n",
    "                        ncm_agl = gpd.overlay(ncm_dis, agl_city, how='intersection')\n",
    "                        print (\"ncm_agl\")\n",
    "\n",
    "                        # Aggregate the area with lower band values (quieter bands)\n",
    "                        ncm_agl_city = gpd.overlay(ncm_agl, agl_city, how='union')\n",
    "                        print (\"union\")\n",
    "\n",
    "                        ncm_agl_city['noisy'] = ncm_agl_city.noisy.fillna(0)\n",
    "                        print (\"fillna\")\n",
    "\n",
    "                        # Select a subset of columns of interest\n",
    "                        ncm_dis = ncm_agl_city[['noisy', 'geometry']]\n",
    "                        print(ncm_dis)\n",
    "                        \n",
    "\n",
    "                        # 3 READ UA DATA        \n",
    "                        # Load GeoPackage info\n",
    "                        data_f = r'A:\\Copernicus\\UrbanAtlas\\UrbanAtlas\\UA2018'\n",
    "                        uc_city = uc_sel.query(f'HDENS_CLST == \"{uc_city_code}\"')\n",
    "                        cityname = uc_city.HDENS_NAME.values.astype(str)[0]\n",
    "                        #city_unicodeName_upper = unidecode(aglo_name).upper()\n",
    "                        city_unicodeName_upper = unidecode(cityname).upper()\n",
    "                        print(city_unicodeName_upper)\n",
    "                        folder_path = glob.glob(os.path.join(data_f, f'{ctry_code}*{city_unicodeName_upper}*'))\n",
    "                        ua_file_path =  glob.glob(os.path.join(folder_path[0], 'Data', f'{ctry_code}*{city_unicodeName_upper}*.gpkg'))\n",
    "                        layers_ls = fiona.listlayers(ua_file_path[0])\n",
    "                        print (\"layers_ls\")\n",
    "\n",
    "                        # Read the GeoPackage file\n",
    "                        ua = gpd.read_file(ua_file_path[0], layer= layers_ls[0], \n",
    "                                        columns= ['country', 'fua_name', 'fua_code','code_2018', 'class_2018', 'geometry'], engine='pyogrio', \n",
    "                                        use_arrow=True, bbox= tuple(uc_city.total_bounds))\n",
    "                        print (\"loaded ua in urban city\")\n",
    "\n",
    "                        # Select 'green' classes\n",
    "                        uagreen = ua.query('code_2018 == \"14100\" or code_2018 == \"31000\"')\n",
    "                        \n",
    "                        # 4 SELECT UA INTERSECTING UC\n",
    "                        # Perform spatial overlay (intersection)\n",
    "                        uagreen_urbc = gpd.overlay(uagreen, uc_city, how='intersection')\n",
    "\n",
    "                        # 5 IDENTIFY GREEN AREAS EXCLUDED (NOT COVERED BY NCM)\n",
    "                        # Perform spatial overlay (intersection)\n",
    "                        nqgreen = gpd.overlay(uagreen_urbc, ncm_dis, how='intersection') #noisy/quiet green\n",
    "                        not_covered = uagreen_urbc.geometry.difference(uagreen_urbc.geometry.intersection(nqgreen.geometry.unary_union))\n",
    "                        # Filter out empty polygons(not empty polygons)\n",
    "                        green_not_covered_by_ncm = not_covered[~not_covered.is_empty]\n",
    "\n",
    "                        # save to shapefile\n",
    "                        file_path = os.path.join(outdata_f, f'{city_agl_cd}_green_not_covered_by_ncm.shp')\n",
    "                        green_not_covered_by_ncm.to_file(file_path, driver='ESRI Shapefile')\n",
    "                        print (\"green_not_covered_by_ncm\")\n",
    "\n",
    "                        # 6 IDENTIFY QUIET/NOISY AREAS\n",
    "                        ## for statistics need to calculate area again\n",
    "                        # Calculate the area for each geometry and create a new column 'area'\n",
    "                        nqgreen['area_m2'] = nqgreen['geometry'].area\n",
    "                        nqgreen['area_ha'] = round(nqgreen['area_m2']* 0.0001,2)\n",
    "                        nqgreen['area_km2'] = round(nqgreen['area_ha']* 0.01,2)\n",
    "                        nqgreen_area = nqgreen.groupby(['code_2018', 'noisy'])['area_m2'].sum().reset_index()\n",
    "                        nqgreen_area['area_ha'] = round(nqgreen_area['area_m2']* 0.0001,2)\n",
    "                        nqgreen_area['area_km2'] = round(nqgreen_area['area_ha']* 0.01,2)\n",
    "\n",
    "                        # 7 EXPORT GREEN QUIET AREAS (GQA)\n",
    "                        nqgreen = nqgreen[['country', 'fua_name', 'fua_code', 'HDENS_2011', 'code_2018', 'class_2018', 'noisy',  'area_m2', 'area_ha', 'area_km2', 'geometry']]\n",
    "                        GQA = nqgreen.query('noisy == 0')\n",
    "                        GNA = nqgreen.query('noisy == 1')\n",
    "\n",
    "                        # Export to shapefile\n",
    "                        file_path = os.path.join(outdata_f, f'{city_agl_cd}_GQA.shp')\n",
    "                        GQA.to_file(file_path, driver='ESRI Shapefile')\n",
    "                        print (\"GQA\")\n",
    "\n",
    "                        # 8 CREATE CENTROIDS FOR GQA POLYGONS\n",
    "                        # Create a new GeoDataFrame with centroids as points\n",
    "                        GQA_pts = gpd.GeoDataFrame(geometry=GQA['geometry'].centroid)\n",
    "                        GQA_pts['oid'] = GQA.index\n",
    "                        GQA_pts['fua_name'] = GQA.fua_name\n",
    "                        GQA_pts['fua_code'] = GQA.fua_code\n",
    "                        GQA_pts['HDENS_2011'] = GQA.HDENS_2011\n",
    "\n",
    "                        # Export to shapefile\n",
    "                        file_path = os.path.join(outdata_f, f'{city_agl_cd}_GQA_centroids.shp')\n",
    "                        GQA_pts.to_file(file_path, driver='ESRI Shapefile')\n",
    "\n",
    "                        print (\"GQA_pts\")\n",
    "                \n",
    "                        # Calculate the duration\n",
    "                        end_time = datetime.now()\n",
    "                        processing_time = end_time - start_time\n",
    "\n",
    "                        print (\"str(processing_time)\")\n",
    "                        \n",
    "                        ## write output values into log file\n",
    "                        uc_km2 = round(uc_city.area.sum()/1000000,2)\n",
    "                        agl_city_km2 = round(agl_city.area.sum()/1000000,2)\n",
    "                        ncm_agl_city_km2 = round(ncm_agl_city.area.sum()/1000000,2)\n",
    "                        ua_km2 = round(ua.area.sum()/1000000,2)\n",
    "                        uagreen_km2 = round(uagreen.area.sum()/1000000,2)\n",
    "                        uagreen_urbc_km2 = round(uagreen_urbc.area.sum()/1000000,2)\n",
    "                        nqgreen_m2 = round(nqgreen.area.sum(),2)\n",
    "                        green_not_covered_by_ncm_m2 = round(green_not_covered_by_ncm.area.sum(),2)\n",
    "                        GQA_m2 = round(GQA.area.sum(),2)\n",
    "                        GNA_m2 = round(GNA.area.sum(),2)\n",
    "                        processing_duration = str(processing_time)\n",
    "\n",
    "                        log_entry = create_log_entry(aglo_name, agl_id, uc_km2, agl_city_km2, \n",
    "                                                ncm_agl_city_km2,ua_km2, uagreen_km2, uagreen_urbc_km2, nqgreen_m2, \n",
    "                                                green_not_covered_by_ncm_m2, GQA_m2, GNA_m2, processing_time)\n",
    "                        write_log(log_path, log_entry)\n",
    "\n",
    "                        # Clean up intermediate variables to free memory\n",
    "                        del agl_city, ncm, ncm_agl, ncm_agl_city, ncm_dis, ua, uagreen, uagreen_urbc, nqgreen, green_not_covered_by_ncm, GQA, GNA, GQA_pts\n",
    "                    except:\n",
    "                        print(\"Error \" + city_agl_cd)\n",
    "                        agl_error_ls.append(city_agl_cd +\" Topological error\")\n",
    "        counter= counter+1\n",
    "\n",
    "print(agl_error_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agl_error_ls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_ETC_DI_v4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
