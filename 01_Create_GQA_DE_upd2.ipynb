{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\geopandas\\_compat.py:123: UserWarning: The Shapely GEOS version (3.11.2-CAPI-1.17.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ubach\\Projects\\GQA\\src\\utils.py:3: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "from src.utils import *\n",
    "\n",
    "# Load required libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import fiona\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from shapely.ops import unary_union\n",
    "from shapely.errors import TopologicalError\n",
    "from unidecode import unidecode\n",
    "import glob\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import dask.dataframe as dd\n",
    "import dask_geopandas as dg\n",
    "from dask.distributed import Client\n",
    "import gc\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\distributed\\node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 52092 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Path to data folders\n",
    "indata_f = r'P:\\Environment and Health\\Noise\\ServiceContract\\2024_ServiceContract\\QuietAreas'\n",
    "outdata_f = os.path.join(indata_f, 'OutputData', 'step1_GQA')\n",
    "if not os.path.exists(outdata_f):\n",
    "    # Create the folder if it doesn't exist\n",
    "    os.makedirs(outdata_f)\n",
    "\n",
    "# 0 PREPARE A LOG FILE FOR QC\n",
    "log_file = 'log_GQA_Step1_231024.csv'\n",
    "log_path = os.path.join(outdata_f, log_file)\n",
    "\n",
    "# Initialize Dask client\n",
    "client = Client()\n",
    "\n",
    "# Define engines\n",
    "engines = {\n",
    "    'fiona': {'engine': 'fiona'},\n",
    "    'pyogrio': {'engine': 'pyogrio'},\n",
    "    'pyogrio+arrow': {'engine': 'pyogrio', 'use_arrow': True}\n",
    "          \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 READ URBAN CENTRES\n",
    "# Read shapefile\n",
    "uc_file_path = os.path.join(indata_f, 'UrbanCentres', 'HDC2021_RG_InputUpdateB2B3B4Copy.shp')\n",
    "# Read the GeoPackage file\n",
    "uc = gpd.read_file(uc_file_path)\n",
    "uc['CNTR_CODE'].fillna('AA', inplace=True)\n",
    "\n",
    "# Select cities for processing in this batch\n",
    "###uc_sel = uc.query('Batch==1.0 & CNTR_CODE != \"SE\"')\n",
    "uc_sel = uc.query('Batch>0.0 and CNTR_CODE==\"DE\"')\n",
    "uc_sel = uc_sel.sort_values(by='CNTR_CODE')\n",
    "\n",
    "# Read table to list the cities to process using urban centre code\n",
    "cities_ls = uc_sel.HDENS_CLST.tolist()\n",
    "len(cities_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEOSTAT21_402\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(i)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m7\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m])\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(code)\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mcities_ls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mlen\u001b[39m(cities_ls)\n",
      "\u001b[1;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "## uc_2remove from conflict folder\n",
    "uc_2remove_path = r'P:\\Environment and Health\\Noise\\ServiceContract\\2024_ServiceContract\\QuietAreas\\OutputData\\oct_run\\GQA_conflictives'\n",
    "shps = glob.glob(os.path.join(uc_2remove_path, '*.shp'))\n",
    "for i in shps:\n",
    "    code = str(os.path.basename(i)[:-7][:-6])\n",
    "    print(code)\n",
    "    cities_ls.remove(str(code))\n",
    "\n",
    "len(cities_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final GQAs\n",
    "QGA_Final_path = r'P:\\Environment and Health\\Noise\\ServiceContract\\2024_ServiceContract\\QuietAreas\\OutputData\\step1_GQA'\n",
    "# Read table with HDENS Urban centres information and Agglomerations link\n",
    "HDENS_AGGL_tbl = pd.read_csv(r'P:\\Environment and Health\\Noise\\ServiceContract\\2024_ServiceContract\\QuietAreas\\Processing\\UrbanCentres_Agglomerations_csv.csv')\n",
    "# Join uc code field to this table\n",
    "HDENS_AGGL_tbl = HDENS_AGGL_tbl.merge(uc[['POPL_2021', 'HDENS_CLST']], on='POPL_2021')\n",
    "\n",
    "# 1 UA DATA FOLDER\n",
    "ua_data_f = r'A:\\Copernicus\\UrbanAtlas\\UrbanAtlas\\UA2018'\n",
    "\n",
    "# 2 READ NOISE DATA\n",
    "# Load agglomerations delineations\n",
    "agls_file_path = os.path.join(indata_f, 'NoiseData', 'DF1_5_Agglomerations_20240429.gpkg')\n",
    "\n",
    "# Read the GeoPackage file\n",
    "agls = gpd.read_file(agls_file_path, layer = 'dbo.DF15_AgglomerationSource_Valid_LatestDelivery', \n",
    "                     **engines['pyogrio+arrow'],columns=['agglomerationId_identifier', 'agglomerationName_nameEng', 'geometry'])\n",
    "\n",
    "# 3 TRANSLATOR TABLE\n",
    "# Crosswalk table containing the different codes from input sources\n",
    "codes_path = r'P:\\Environment and Health\\Noise\\ServiceContract\\2024_ServiceContract\\QuietAreas\\Processing\\Codes.csv'\n",
    "codes = pd.read_csv(codes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_ls = sorted(cities_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GEOSTAT21_925']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_ls[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2024-10-31 12:48:03.413600\n",
      "DE-GEOSTAT21_925-AG_DE_NW_19-Solingen\n",
      "Loading agglomeration boundary for selected city\n",
      "DE-GEOSTAT21_925-AG_DE_NW_7-Wuppertal\n",
      "Loading agglomeration boundary for selected city\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "counter= 1\n",
    "agl_error_ls = []\n",
    "\n",
    "# Loop through test cities\n",
    "for uc_city_code in cities_ls[-1:]:\n",
    "    print(counter)\n",
    "    start_time = datetime.now()\n",
    "    print(str(start_time))\n",
    "\n",
    "    ua_path = codes.query(f'HDENS_CLST==\"{uc_city_code}\"').UA2018.values[0].strip()\n",
    "    if ua_path == 'not available':\n",
    "        agl_error_ls.append(uc_city_code +\" UA not available\")\n",
    "    \n",
    "    else:\n",
    "        inGQA = os.path.join(QGA_Final_path, '{}_finalGQA.shp'.format(uc_city_code))\n",
    "        if not os.path.exists(inGQA):\n",
    "            urban_center = uc.query(f'HDENS_CLST==\"{uc_city_code}\"')\n",
    "            HDENS_AGGL_city = HDENS_AGGL_tbl.query(f\"HDENS_CLST=='{uc_city_code}'\")\n",
    "            agl_id_city_ls = HDENS_AGGL_city.agglomerationId_identifier.values.astype(str).tolist()\n",
    "            for agl_id in agl_id_city_ls:\n",
    "                HDENS_AGGL_city_aglid = HDENS_AGGL_tbl.query(f\"HDENS_CLST=='{uc_city_code}' & agglomerationId_identifier=='{agl_id}'\")\n",
    "                ctry_code = HDENS_AGGL_city_aglid.CNTR_CODE.values.astype(str)[0]\n",
    "                aglo_name = HDENS_AGGL_city_aglid.agglomerationName_nameEng.values.astype(str)[0]\n",
    "                aglo_name = aglo_name.split('/')[0]\n",
    "                aglo_name = aglo_name.split(' ')[0]\n",
    "\n",
    "                if len(ctry_code.split('-'))>1:\n",
    "                    print(F'>1 countries {ctry_code}')\n",
    "                    ctry_code = ctry_code.split('-')[0]\n",
    "                \n",
    "                city_agl_cd = f\"{ctry_code}-{uc_city_code}-{agl_id}-{aglo_name}\"\n",
    "                print(city_agl_cd)\n",
    "                if ctry_code=='DE':\n",
    "                    print('Loading agglomeration boundary for selected city')      \n",
    "                    # Load agglomeration boundary for selected city\n",
    "                    agl_city = agls.query(f'agglomerationId_identifier == \"{agl_id}\"')\n",
    "                    if agl_city.empty:\n",
    "                        agglomerationId_identifier = 'NotAvailable'\n",
    "                        print (\"agglomerationId_identifier Not Available\")\n",
    "                        agl_error_ls.append(city_agl_cd + \" agglomerationId_identifier Not Available\")\n",
    "                    else:\n",
    "                        GQA_uc_aglo_path = os.path.join(outdata_f, f'{city_agl_cd}_GQA.shp')\n",
    "                        if not os.path.exists(GQA_uc_aglo_path):\n",
    "                            try:\n",
    "                                # Check noise contour maps GeoPackage file\n",
    "                                ncm_file_path = os.path.join(indata_f, 'NoiseData', f'Noise_20202025_export.gpkg')\n",
    "                                layerName = f'dbo.DF48_agg_NoiseContours_roadsInAgglomeration_Lden_Valid_LatestDelivery_Poly_{ctry_code}'           \n",
    "                                #ncm_file_path = os.path.join(indata_f, 'NoiseData', f'Noise_20202025_export_{ctry_code}.gpkg')\n",
    "                                #layerName = f'dbo.DF48_agg_NoiseContours_roadsInAgglomeration_Lden_Valid_LatestDelivery_Poly_{ctry_code}'\n",
    "                                #layerName = f'dbodf48_agg_noisecontours_roadsinagglomeration_lden_valid_latestdelivery_poly_{ctry_code}'\n",
    "                                ncm = gpd.read_file(ncm_file_path, layer=layerName, columns=['category', 'geometry'], \n",
    "                                                    engine='pyogrio', use_arrow=True, bbox= tuple(agl_city.total_bounds))\n",
    "                                print (\"ncm\")\n",
    "\n",
    "                                ncm = gpd.clip(ncm, agl_city)\n",
    "\n",
    "                                # Define the list of noisy classes\n",
    "                                noisy_classes = ['Lden5559', 'Lden6064', 'Lden6569', 'Lden7074', 'LdenGreaterThan75']\n",
    "                                print(noisy_classes)\n",
    "                                # Create a condition based on the category column\n",
    "                                condition = ncm['category'].isin(noisy_classes)  # Replace 'category_column' with the actual column name\n",
    "\n",
    "                                # Specify the condition and create a new category column based on the condition\n",
    "                                ncm['noisy'] = 0\n",
    "                                ncm.loc[condition, 'noisy'] = 1\n",
    "                                ncm = ncm[['noisy', 'geometry']]\n",
    "                                print(ncm)\n",
    "                                ncm_dis_dg = dg.from_geopandas(ncm, npartitions=10)\n",
    "                                ncm_dis = ncm_dis_dg.dissolve(by='noisy').compute().reset_index()\n",
    "                                print (\"ncm_dis\")\n",
    "\n",
    "                                # Perform spatial overlay (intersection) \n",
    "                                ncm_agl = gpd.overlay(ncm_dis, agl_city, how='intersection')\n",
    "                                print (\"ncm_agl\")\n",
    "\n",
    "                                # Aggregate the area with lower band values (quieter bands)\n",
    "                                ncm_agl_city = gpd.overlay(ncm_agl, agl_city, how='union')\n",
    "                                print (\"union\")\n",
    "\n",
    "                                ncm_agl_city['noisy'] = ncm_agl_city.noisy.fillna(0)\n",
    "                                print (\"fillna\")\n",
    "\n",
    "                                # Select a subset of columns of interest\n",
    "                                ncm_dis = ncm_agl_city[['noisy', 'geometry']]\n",
    "                                print(ncm_dis)\n",
    "                                \n",
    "\n",
    "                                # 3 READ URBAN ATLAS DATA       \n",
    "                                file_path = os.path.join(ua_data_f, f'{ua_path}\\Data\\{ua_path}.gpkg')\n",
    "                                # Read the GeoPackage file\n",
    "                                ua = gpd.read_file(file_path, layer= ua_path[:-5], \n",
    "                                            columns= ['country', 'fua_name', 'fua_code','code_2018', 'class_2018', 'geometry'], \n",
    "                                            engine='pyogrio', \n",
    "                                            use_arrow=True, bbox= tuple(urban_center.total_bounds))\n",
    "                                print (\"loaded ua in urban city\")                        \n",
    "\n",
    "                                # Select 'green' classes\n",
    "                                uagreen = ua.query('code_2018 == \"14100\" or code_2018 == \"31000\"')\n",
    "                                \n",
    "                                # 4 SELECT UA INTERSECTING UC\n",
    "                                # Perform spatial overlay (intersection)\n",
    "                                uagreen_urbc = gpd.overlay(uagreen, urban_center, how='intersection')\n",
    "\n",
    "                                # 5 IDENTIFY GREEN AREAS EXCLUDED (NOT COVERED BY NCM)\n",
    "                                # Perform spatial overlay (intersection)\n",
    "                                nqgreen = gpd.overlay(uagreen_urbc, ncm_dis, how='intersection') #noisy/quiet green\n",
    "                                not_covered = uagreen_urbc.geometry.difference(uagreen_urbc.geometry.intersection(nqgreen.geometry.unary_union))\n",
    "                                # Filter out empty polygons(not empty polygons)\n",
    "                                green_not_covered_by_ncm = not_covered[~not_covered.is_empty]\n",
    "\n",
    "                                # save to shapefile\n",
    "                                file_path = os.path.join(outdata_f, f'{city_agl_cd}_green_not_covered_by_ncm.shp')\n",
    "                                #green_not_covered_by_ncm.to_file(file_path, driver='ESRI Shapefile')\n",
    "                                print (\"green_not_covered_by_ncm\")\n",
    "\n",
    "                                # 6 IDENTIFY QUIET/NOISY AREAS\n",
    "                                ## for statistics need to calculate area again\n",
    "                                # Calculate the area for each geometry and create a new column 'area'\n",
    "                                nqgreen['area_m2'] = nqgreen['geometry'].area\n",
    "                                nqgreen['area_ha'] = round(nqgreen['area_m2']* 0.0001,2)\n",
    "                                nqgreen['area_km2'] = round(nqgreen['area_ha']* 0.01,2)\n",
    "                                nqgreen_area = nqgreen.groupby(['code_2018', 'noisy'])['area_m2'].sum().reset_index()\n",
    "                                nqgreen_area['area_ha'] = round(nqgreen_area['area_m2']* 0.0001,2)\n",
    "                                nqgreen_area['area_km2'] = round(nqgreen_area['area_ha']* 0.01,2)\n",
    "\n",
    "                                # 7 EXPORT GREEN QUIET AREAS (GQA)\n",
    "                                nqgreen = nqgreen[['country', 'fua_name', 'fua_code', 'HDENS_2011', 'code_2018', 'class_2018', 'noisy',  'area_m2', 'area_ha', 'area_km2', 'geometry']]\n",
    "                                GQA = nqgreen.query('noisy == 0')\n",
    "                                GNA = nqgreen.query('noisy == 1')\n",
    "\n",
    "                                # Export to shapefile\n",
    "                                print ('Export to shapefile')\n",
    "                                \n",
    "                                print (GQA_uc_aglo_path)\n",
    "                                GQA.to_file(GQA_uc_aglo_path, driver='ESRI Shapefile')\n",
    "                                print (\"GQA\")\n",
    "\n",
    "                                # 8 CREATE CENTROIDS FOR GQA POLYGONS\n",
    "                                # Create a new GeoDataFrame with centroids as points\n",
    "                                GQA_pts = gpd.GeoDataFrame(geometry=GQA['geometry'].centroid)\n",
    "                                GQA_pts['oid'] = GQA.index\n",
    "                                GQA_pts['fua_name'] = GQA.fua_name\n",
    "                                GQA_pts['fua_code'] = GQA.fua_code\n",
    "                                GQA_pts['HDENS_2011'] = GQA.HDENS_2011\n",
    "\n",
    "                                # Export to shapefile\n",
    "                                file_path = os.path.join(outdata_f, f'{city_agl_cd}_GQA_centroids.shp')\n",
    "                                GQA_pts.to_file(file_path, driver='ESRI Shapefile')\n",
    "\n",
    "                                print (\"GQA_pts\")\n",
    "                        \n",
    "                                # Calculate the duration\n",
    "                                end_time = datetime.now()\n",
    "                                processing_time = end_time - start_time\n",
    "\n",
    "                                print (\"str(processing_time)\")\n",
    "                                \n",
    "                                ## write output values into log file\n",
    "                                uc_km2 = round(uc_city.area.sum()/1000000,2)\n",
    "                                agl_city_km2 = round(agl_city.area.sum()/1000000,2)\n",
    "                                ncm_agl_city_km2 = round(ncm_agl_city.area.sum()/1000000,2)\n",
    "                                ua_km2 = round(ua.area.sum()/1000000,2)\n",
    "                                uagreen_km2 = round(uagreen.area.sum()/1000000,2)\n",
    "                                uagreen_urbc_km2 = round(uagreen_urbc.area.sum()/1000000,2)\n",
    "                                nqgreen_m2 = round(nqgreen.area.sum(),2)\n",
    "                                green_not_covered_by_ncm_m2 = round(green_not_covered_by_ncm.area.sum(),2)\n",
    "                                GQA_m2 = round(GQA.area.sum(),2)\n",
    "                                GNA_m2 = round(GNA.area.sum(),2)\n",
    "                                processing_duration = str(processing_time)\n",
    "\n",
    "                                log_entry = create_log_entry(aglo_name, agl_id, uc_km2, agl_city_km2, \n",
    "                                                        ncm_agl_city_km2,ua_km2, uagreen_km2, uagreen_urbc_km2, nqgreen_m2, \n",
    "                                                        green_not_covered_by_ncm_m2, GQA_m2, GNA_m2, processing_time)\n",
    "                                write_log(log_path, log_entry)\n",
    "\n",
    "                                # Clean up intermediate variables to free memory\n",
    "                                del agl_city, ncm, ncm_agl, ncm_agl_city, ncm_dis, ua, uagreen, uagreen_urbc, nqgreen, green_not_covered_by_ncm, GQA, GNA, GQA_pts\n",
    "                            except:\n",
    "                                print(\"Error \" + city_agl_cd)\n",
    "                                agl_error_ls.append(city_agl_cd +\" Topological error\")\n",
    "    counter= counter+1\n",
    "\n",
    "print(agl_error_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P:\\\\Environment and Health\\\\Noise\\\\ServiceContract\\\\2024_ServiceContract\\\\QuietAreas\\\\OutputData\\\\step1_GQA\\\\DE-GEOSTAT21_925-AG_DE_NW_7-Wuppertal_GQA.shp'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GQA_uc_aglo_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agglomerationId_identifier</th>\n",
       "      <th>agglomerationName_nameEng</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>AG_DE_NW_7</td>\n",
       "      <td>Wuppertal</td>\n",
       "      <td>MULTIPOLYGON (((4114455.585 3131062.616, 41144...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    agglomerationId_identifier agglomerationName_nameEng  \\\n",
       "205                 AG_DE_NW_7                 Wuppertal   \n",
       "\n",
       "                                              geometry  \n",
       "205  MULTIPOLYGON (((4114455.585 3131062.616, 41144...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agl_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncm_file_path = os.path.join(indata_f, 'NoiseData', f'Noise_20202025_export.gpkg')\n",
    "layerName = f'dbo.DF48_agg_NoiseContours_roadsInAgglomeration_Lden_Valid_LatestDelivery_Poly_{ctry_code}'           \n",
    "#ncm_file_path = os.path.join(indata_f, 'NoiseData', f'Noise_20202025_export_{ctry_code}.gpkg')\n",
    "#layerName = f'dbo.DF48_agg_NoiseContours_roadsInAgglomeration_Lden_Valid_LatestDelivery_Poly_{ctry_code}'\n",
    "#layerName = f'dbodf48_agg_noisecontours_roadsinagglomeration_lden_valid_latestdelivery_poly_{ctry_code}'\n",
    "ncm = gpd.read_file(ncm_file_path, layer=layerName, columns=['category', 'geometry'], \n",
    "                    engine='pyogrio', use_arrow=True, bbox= tuple(agl_city.total_bounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncm = gpd.clip(ncm, agl_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agglomerationId_identifier</th>\n",
       "      <th>agglomerationName_nameEng</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>AG_DE_NW_7</td>\n",
       "      <td>Wuppertal</td>\n",
       "      <td>MULTIPOLYGON (((4114455.585 3131062.616, 41144...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    agglomerationId_identifier agglomerationName_nameEng  \\\n",
       "205                 AG_DE_NW_7                 Wuppertal   \n",
       "\n",
       "                                              geometry  \n",
       "205  MULTIPOLYGON (((4114455.585 3131062.616, 41144...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agl_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DE-GEOSTAT21_305-AG_DE_NW_16-Hagen Topological error',\n",
       " 'DE-GEOSTAT21_302-AG_DE_NW_2-Duesseldorf Topological error',\n",
       " 'DE-GEOSTAT21_302-AG_DE_NW_5-Duisburg Topological error',\n",
       " 'DE-GEOSTAT21_302-AG_DE_NW_17-Muelheim Topological error',\n",
       " 'DE-GEOSTAT21_297-AG_DE_NW_5-Duisburg Topological error',\n",
       " 'DE-GEOSTAT21_297-AG_DE_NW_14-Krefeld Topological error',\n",
       " 'DE-GEOSTAT21_297-AG_DE_NW_26-Moers Topological error',\n",
       " 'DE-GEOSTAT21_334-AG_DE_NW_2-Duesseldorf Topological error',\n",
       " 'DE-GEOSTAT21_299-AG_DE_NW_6-Bochum Topological error',\n",
       " 'DE-GEOSTAT21_299-AG_DE_NW_22-Bottrop Topological error',\n",
       " 'DE-GEOSTAT21_299-AG_DE_NW_3-Dortmund Topological error',\n",
       " 'DE-GEOSTAT21_299-AG_DE_NW_5-Duisburg Topological error',\n",
       " 'DE-GEOSTAT21_299-AG_DE_NW_4-Essen Topological error',\n",
       " 'DE-GEOSTAT21_299-AG_DE_NW_11-Gelsenkirchen Topological error',\n",
       " 'DE-GEOSTAT21_299-AG_DE_NW_20-Herne Topological error',\n",
       " 'DE-GEOSTAT21_299-AG_DE_NW_17-Muelheim Topological error',\n",
       " 'DE-GEOSTAT21_299-AG_DE_NW_15-Oberhausen Topological error',\n",
       " 'DE-GEOSTAT21_299-AG_DE_NW_23-Recklinghausen Topological error']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agl_error_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\contextlib.py:119: UserWarning: Measured (M) geometry types are not supported. Original type 'Measured 3D MultiPolygon' is converted to 'MultiPolygon Z'\n",
      "  return next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncm\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import MultiPolygon\n",
    "\n",
    "# Assuming you have a GeoDataFrame with measured geometry\n",
    "ncm_file_path = os.path.join(indata_f, 'NoiseData', f'Noise_20202025_export_DE_update.gpkg')\n",
    "layerName = f'dbo.DF48_agg_NoiseContours_roadsInAgglomeration_Lden_Valid_LatestDelivery_Poly_DE' \n",
    "ncm = gpd.read_file(ncm_file_path, layer=layerName, columns=['category', 'geometry'], engine='pyogrio', use_arrow=True)\n",
    "print (\"ncm\")\n",
    "\n",
    "gdf = ncm\n",
    "\n",
    "# Function to remove the M dimension\n",
    "def strip_m_dimension(geometry):\n",
    "    # Convert to WKT (Well-Known Text) to remove M\n",
    "    if geometry.has_z:\n",
    "        return MultiPolygon([geom for geom in geometry.geoms])  # Preserve Z if needed\n",
    "    else:\n",
    "        return geometry  # If it's already a standard geometry\n",
    "\n",
    "# Apply the function to your GeoDataFrame\n",
    "gdf['geometry'] = gdf['geometry'].apply(strip_m_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncm_file_path = os.path.join(indata_f, 'NoiseData', f'Noise_20202025_export_DE_update_v2.gpkg')\n",
    "gdf.to_file(ncm_file_path, driver='GPKG', layer='ncm_DE_upd')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2024-10-23 13:14:49.146948\n",
      "2\n",
      "2024-10-23 13:14:49.162948\n",
      "DE-GEOSTAT21_305-AG_DE_NW_16-Hagen\n",
      "Loading agglomeration boundary for selected city\n",
      "ncm\n"
     ]
    }
   ],
   "source": [
    "counter= 1\n",
    "agl_error_ls = []\n",
    "\n",
    "# Loop through test cities\n",
    "for uc_city_code in cities_ls:\n",
    "    print(counter)\n",
    "    start_time = datetime.now()\n",
    "    print(str(start_time))\n",
    "\n",
    "    ua_path = codes.query(f'HDENS_CLST==\"{uc_city_code}\"').UA2018.values[0].strip()\n",
    "    if ua_path == 'not available':\n",
    "        agl_error_ls.append(uc_city_code +\" UA not available\")\n",
    "    \n",
    "    else:\n",
    "        inGQA = os.path.join(QGA_Final_path, '{}_finalGQA.shp'.format(uc_city_code))\n",
    "        if not os.path.exists(inGQA):\n",
    "            urban_center = uc.query(f'HDENS_CLST==\"{uc_city_code}\"')\n",
    "            HDENS_AGGL_city = HDENS_AGGL_tbl.query(f\"HDENS_CLST=='{uc_city_code}'\")\n",
    "            agl_id_city_ls = HDENS_AGGL_city.agglomerationId_identifier.values.astype(str).tolist()\n",
    "            for agl_id in agl_id_city_ls:\n",
    "                HDENS_AGGL_city_aglid = HDENS_AGGL_tbl.query(f\"HDENS_CLST=='{uc_city_code}' & agglomerationId_identifier=='{agl_id}'\")\n",
    "                ctry_code = HDENS_AGGL_city_aglid.CNTR_CODE.values.astype(str)[0]\n",
    "                aglo_name = HDENS_AGGL_city_aglid.agglomerationName_nameEng.values.astype(str)[0]\n",
    "                aglo_name = aglo_name.split('/')[0]\n",
    "                aglo_name = aglo_name.split(' ')[0]\n",
    "\n",
    "                if len(ctry_code.split('-'))>1:\n",
    "                    print(F'>1 countries {ctry_code}')\n",
    "                    ctry_code = ctry_code.split('-')[0]\n",
    "                \n",
    "                city_agl_cd = f\"{ctry_code}-{uc_city_code}-{agl_id}-{aglo_name}\"\n",
    "                print(city_agl_cd)\n",
    "                if ctry_code=='DE':\n",
    "                    print('Loading agglomeration boundary for selected city')      \n",
    "                    # Load agglomeration boundary for selected city\n",
    "                    agl_city = agls.query(f'agglomerationId_identifier == \"{agl_id}\"')\n",
    "                    if agl_city.empty:\n",
    "                        agglomerationId_identifier = 'NotAvailable'\n",
    "                        print (\"agglomerationId_identifier Not Available\")\n",
    "                        agl_error_ls.append(city_agl_cd + \" agglomerationId_identifier Not Available\")\n",
    "                    else:\n",
    "                        output_path = os.path.join(outdata_f, f'{city_agl_cd}_GQA_centroids.shp')\n",
    "                        if not os.path.exists(output_path):\n",
    "                            try:\n",
    "                                # Check noise contour maps GeoPackage file\n",
    "                                ncm_file_path = os.path.join(indata_f, 'NoiseData', f'Noise_20202025_export_DE_update_v2.gpkg')\n",
    "                                layerName = f'ncm_DE_upd'           \n",
    "                                #ncm_file_path = os.path.join(indata_f, 'NoiseData', f'Noise_20202025_export_{ctry_code}.gpkg')\n",
    "                                #layerName = f'dbo.DF48_agg_NoiseContours_roadsInAgglomeration_Lden_Valid_LatestDelivery_Poly_{ctry_code}'\n",
    "                                #layerName = f'dbodf48_agg_noisecontours_roadsinagglomeration_lden_valid_latestdelivery_poly_{ctry_code}'\n",
    "                                ncm = gpd.read_file(ncm_file_path, layer=layerName, columns=['category', 'geometry'], \n",
    "                                                    engine='pyogrio', use_arrow=True, bbox= tuple(agl_city.total_bounds))\n",
    "                                print (\"ncm\")\n",
    "\n",
    "                                # Define the list of noisy classes\n",
    "                                noisy_classes = ['Lden5559', 'Lden6064', 'Lden6569', 'Lden7074', 'LdenGreaterThan75']\n",
    "\n",
    "                                # Create a condition based on the category column\n",
    "                                condition = ncm['category'].isin(noisy_classes)  # Replace 'category_column' with the actual column name\n",
    "\n",
    "                                # Specify the condition and create a new category column based on the condition\n",
    "                                ncm['noisy'] = 0\n",
    "                                ncm.loc[condition, 'noisy'] = 1\n",
    "                                ncm = ncm[['noisy', 'geometry']]\n",
    "                                ncm_dis_dg = dg.from_geopandas(ncm, npartitions=10)\n",
    "                                ncm_dis = ncm_dis_dg.dissolve(by='noisy').compute().reset_index()\n",
    "                                print (\"ncm_dis\")\n",
    "\n",
    "                                # Perform spatial overlay (intersection) \n",
    "                                ncm_agl = gpd.overlay(ncm_dis, agl_city, how='intersection')\n",
    "                                print (\"ncm_agl\")\n",
    "\n",
    "                                # Aggregate the area with lower band values (quieter bands)\n",
    "                                ncm_agl_city = gpd.overlay(ncm_agl, agl_city, how='union')\n",
    "                                print (\"union\")\n",
    "\n",
    "                                ncm_agl_city['noisy'] = ncm_agl_city.noisy.fillna(0)\n",
    "                                print (\"fillna\")\n",
    "\n",
    "                                # Select a subset of columns of interest\n",
    "                                ncm_dis = ncm_agl_city[['noisy', 'geometry']]\n",
    "                                print(ncm_dis)\n",
    "                                \n",
    "\n",
    "                                # 3 READ URBAN ATLAS DATA       \n",
    "                                file_path = os.path.join(ua_data_f, f'{ua_path}\\Data\\{ua_path}.gpkg')\n",
    "                                # Read the GeoPackage file\n",
    "                                ua = gpd.read_file(file_path, layer= ua_path[:-5], \n",
    "                                            columns= ['country', 'fua_name', 'fua_code','code_2018', 'class_2018', 'geometry'], \n",
    "                                            engine='pyogrio', \n",
    "                                            use_arrow=True, bbox= tuple(urban_center.total_bounds))\n",
    "                                print (\"loaded ua in urban city\")                        \n",
    "\n",
    "                                # Select 'green' classes\n",
    "                                uagreen = ua.query('code_2018 == \"14100\" or code_2018 == \"31000\"')\n",
    "                                \n",
    "                                # 4 SELECT UA INTERSECTING UC\n",
    "                                # Perform spatial overlay (intersection)\n",
    "                                uagreen_urbc = gpd.overlay(uagreen, urban_center, how='intersection')\n",
    "\n",
    "                                # 5 IDENTIFY GREEN AREAS EXCLUDED (NOT COVERED BY NCM)\n",
    "                                # Perform spatial overlay (intersection)\n",
    "                                nqgreen = gpd.overlay(uagreen_urbc, ncm_dis, how='intersection') #noisy/quiet green\n",
    "                                not_covered = uagreen_urbc.geometry.difference(uagreen_urbc.geometry.intersection(nqgreen.geometry.unary_union))\n",
    "                                # Filter out empty polygons(not empty polygons)\n",
    "                                green_not_covered_by_ncm = not_covered[~not_covered.is_empty]\n",
    "\n",
    "                                # save to shapefile\n",
    "                                file_path = os.path.join(outdata_f, f'{city_agl_cd}_green_not_covered_by_ncm.shp')\n",
    "                                #green_not_covered_by_ncm.to_file(file_path, driver='ESRI Shapefile')\n",
    "                                print (\"green_not_covered_by_ncm\")\n",
    "\n",
    "                                # 6 IDENTIFY QUIET/NOISY AREAS\n",
    "                                ## for statistics need to calculate area again\n",
    "                                # Calculate the area for each geometry and create a new column 'area'\n",
    "                                nqgreen['area_m2'] = nqgreen['geometry'].area\n",
    "                                nqgreen['area_ha'] = round(nqgreen['area_m2']* 0.0001,2)\n",
    "                                nqgreen['area_km2'] = round(nqgreen['area_ha']* 0.01,2)\n",
    "                                nqgreen_area = nqgreen.groupby(['code_2018', 'noisy'])['area_m2'].sum().reset_index()\n",
    "                                nqgreen_area['area_ha'] = round(nqgreen_area['area_m2']* 0.0001,2)\n",
    "                                nqgreen_area['area_km2'] = round(nqgreen_area['area_ha']* 0.01,2)\n",
    "\n",
    "                                # 7 EXPORT GREEN QUIET AREAS (GQA)\n",
    "                                nqgreen = nqgreen[['country', 'fua_name', 'fua_code', 'HDENS_2011', 'code_2018', 'class_2018', 'noisy',  'area_m2', 'area_ha', 'area_km2', 'geometry']]\n",
    "                                GQA = nqgreen.query('noisy == 0')\n",
    "                                GNA = nqgreen.query('noisy == 1')\n",
    "\n",
    "                                # Export to shapefile\n",
    "                                print ('Export to shapefile')\n",
    "                                GQA_uc_aglo_path = os.path.join(outdata_f, f'{city_agl_cd}_GQA.shp')\n",
    "                                print (GQA_uc_aglo_path)\n",
    "                                GQA.to_file(GQA_uc_aglo_path, driver='ESRI Shapefile')\n",
    "                                print (\"GQA\")\n",
    "\n",
    "                                # 8 CREATE CENTROIDS FOR GQA POLYGONS\n",
    "                                # Create a new GeoDataFrame with centroids as points\n",
    "                                GQA_pts = gpd.GeoDataFrame(geometry=GQA['geometry'].centroid)\n",
    "                                GQA_pts['oid'] = GQA.index\n",
    "                                GQA_pts['fua_name'] = GQA.fua_name\n",
    "                                GQA_pts['fua_code'] = GQA.fua_code\n",
    "                                GQA_pts['HDENS_2011'] = GQA.HDENS_2011\n",
    "\n",
    "                                # Export to shapefile\n",
    "                                file_path = os.path.join(outdata_f, f'{city_agl_cd}_GQA_centroids.shp')\n",
    "                                GQA_pts.to_file(file_path, driver='ESRI Shapefile')\n",
    "\n",
    "                                print (\"GQA_pts\")\n",
    "                        \n",
    "                                # Calculate the duration\n",
    "                                end_time = datetime.now()\n",
    "                                processing_time = end_time - start_time\n",
    "\n",
    "                                print (\"str(processing_time)\")\n",
    "                                \n",
    "                                ## write output values into log file\n",
    "                                uc_km2 = round(uc_city.area.sum()/1000000,2)\n",
    "                                agl_city_km2 = round(agl_city.area.sum()/1000000,2)\n",
    "                                ncm_agl_city_km2 = round(ncm_agl_city.area.sum()/1000000,2)\n",
    "                                ua_km2 = round(ua.area.sum()/1000000,2)\n",
    "                                uagreen_km2 = round(uagreen.area.sum()/1000000,2)\n",
    "                                uagreen_urbc_km2 = round(uagreen_urbc.area.sum()/1000000,2)\n",
    "                                nqgreen_m2 = round(nqgreen.area.sum(),2)\n",
    "                                green_not_covered_by_ncm_m2 = round(green_not_covered_by_ncm.area.sum(),2)\n",
    "                                GQA_m2 = round(GQA.area.sum(),2)\n",
    "                                GNA_m2 = round(GNA.area.sum(),2)\n",
    "                                processing_duration = str(processing_time)\n",
    "\n",
    "                                log_entry = create_log_entry(aglo_name, agl_id, uc_km2, agl_city_km2, \n",
    "                                                        ncm_agl_city_km2,ua_km2, uagreen_km2, uagreen_urbc_km2, nqgreen_m2, \n",
    "                                                        green_not_covered_by_ncm_m2, GQA_m2, GNA_m2, processing_time)\n",
    "                                write_log(log_path, log_entry)\n",
    "\n",
    "                                # Clean up intermediate variables to free memory\n",
    "                                del agl_city, ncm, ncm_agl, ncm_agl_city, ncm_dis, ua, uagreen, uagreen_urbc, nqgreen, green_not_covered_by_ncm, GQA, GNA, GQA_pts\n",
    "                            except:\n",
    "                                print(\"Error \" + city_agl_cd)\n",
    "                                agl_error_ls.append(city_agl_cd +\" Topological error\")\n",
    "    counter= counter+1\n",
    "\n",
    "print(agl_error_ls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_ETC_DI_v4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
